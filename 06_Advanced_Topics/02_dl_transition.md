# 與深度學習銜接（Transition to Deep Learning）

---

## 一、為什麼需要深度學習？

深度學習是機器學習的子集，利用**多層神經網路**處理大量且高維度資料，克服傳統 ML 難以應對的複雜模式辨識問題。

### 適用場景：

- **高維資料**：如影像（像素矩陣）、語音（頻譜）、文本（字詞序列）
- **無法手動提取特徵**：如風格分類、語意理解、語音辨識等
- **需 end-to-end 模型**：自動從資料學習抽象特徵與決策

---

## 二、傳統 ML 與 DL 差異比較

| 項目            | 傳統機器學習（ML）        | 深度學習（DL）                      |
|-----------------|----------------------------|-------------------------------------|
| 特徵工程        | 需手動設計特徵             | 模型自動學習特徵                    |
| 資料需求        | 中小型資料集                | 需大量資料                         |
| 模型解釋性      | 較高                        | 較低（可搭配可視化輔助）            |
| 訓練資源        | 較低，CPU 可處理            | 高，需 GPU/TPU 支援                 |
| 訓練時間        | 快                          | 較慢（可透過並行、剪枝加速）        |
| 應用場景        | 表格資料、結構化資料        | 圖像、語音、文本、序列資料         |

---

## 三、PyTorch 神經網路簡化範例

以下為用 PyTorch 建立一個簡單的 2 層全連接神經網路（如手寫數字辨識）：

```python
import torch.nn as nn

model = nn.Sequential(
    nn.Linear(784, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)
```

> 輸入維度 784（28x28 圖片展平），輸出為 10 類（數字 0~9）

---

## 四、典型應用場景

| 領域         | 技術                      | 案例                           |
|--------------|---------------------------|--------------------------------|
| 影像處理     | CNN 卷積神經網路          | 影像分類、人臉辨識、物件偵測   |
| 語音處理     | RNN / Transformer         | 語音辨識、自動生成語音         |
| 自然語言處理 | Transformer / BERT        | 情感分析、問答系統、翻譯       |
| 生成模型     | GAN / Diffusion Models    | 影像合成、圖像風格轉換         |
| 時序預測     | LSTM / GRU / TCN           | 股價預測、氣象預測、IoT 資料   |

---

## 五、銜接建議

- 熟悉 `torch.nn`, `torch.optim`, `Dataset` / `Dataloader` 等基礎 API
- 多從「表格資料 → 影像 / 文本」應用作為轉換切點
- 可以從 MLP 模型開始過渡至 CNN、RNN、Transformer
- 使用 PyTorch Lightning 等框架提升實作效率

---
